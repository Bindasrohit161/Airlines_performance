{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774b1aad",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime, date\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# import seaborn as sns\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# import matplotlib.pyplot as plt\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# from scipy import stats\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.append('/Users/bernardoloureiro/template-lib')\n",
    "\n",
    "from utils.notebookhelpers.helpers import Helpers\n",
    "from utils.dtos.templateOutputCollection import TemplateOutputCollection\n",
    "from utils.dtos.variable import Metadata\n",
    "from utils.dtos.templateOutput import TemplateOutput\n",
    "from utils.dtos.templateOutput import OutputType\n",
    "from utils.dtos.templateOutput import ChartType\n",
    "import logging\n",
    "import os\n",
    "from dateutil import parser\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "# !pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', 500000)\n",
    "pd.set_option('display.max_columns', 50000)\n",
    "pd.set_option('display.width', 10000)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, date\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "# from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b73b5bb-e887-427c-9b0b-0762ee92fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the context\n",
    "contextId = 'Airline_performance'\n",
    "context = Helpers.getOrCreateContext(contextId=contextId, localVars=locals())\n",
    "\n",
    "inputDatasetParameter=Helpers.get_or_create_input_dataset(\n",
    "    name=\"inputDataset2\",\n",
    "    metadata=Metadata(input_name='inputDataset2', is_required=True, tooltip='output transformation'),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Airline_Parameter = Helpers.get_or_create_input_var(name=\"Airline\",\n",
    "#     metadata=Metadata(input_name=\"Airline\", is_required=True, tooltip=\"All Airline names\", multiple=False, datatypes=['STRING'],options=['FIELDS', 'CONSTANT'], datasets=['inputDataset']),\n",
    "#     local_context=locals()\n",
    "#     )\n",
    "\n",
    "Departures_On_Time_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Departures_On_Time\",\n",
    "    metadata=Metadata(input_name=\"Departures_On_Time\", is_required=True, tooltip=\"All Departures_On_Time\", multiple=False,datatypes=['STRING'] ,options=['FIELDS', 'CONSTANT'], datasets=['inputDataset']),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "# Departures_Delayed_Parameter = Helpers.get_or_create_input_var(\n",
    "#     name=\"Departures_Delayed\",\n",
    "#     metadata=Metadata(input_name=\"Departures_Delayed\", is_required=True, tooltip=\"All Departures_On_Time\", multiple=False, datatypes=['STRING'],options=['FIELDS', 'CONSTANT'], datasets=['inputDataset']),\n",
    "#     local_context=locals()\n",
    "# )\n",
    "\n",
    "Total_scheduled_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Total_scheduled\",\n",
    "    metadata=Metadata(input_name=\"Total_scheduled\", is_required=True, tooltip=\"All Departures_On_Time\", multiple=False, datatypes=['STRING'],options=['FIELDS', 'CONSTANT'], datasets=['inputDataset']),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "Total_departed_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Total_departed\",\n",
    "    metadata=Metadata(input_name=\"Total_departed\", is_required=True, tooltip=\"All Departures_On_Time\", multiple=False, datatypes=['STRING'],options=['FIELDS', 'CONSTANT'], datasets=['inputDataset']),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "Airline_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Airline\",\n",
    "    metadata=Metadata(input_name=\"Airline\", is_required=True, tooltip=\"All Departures_On_Time\", multiple=False, datatypes=['STRING'],options=['FIELDS', 'CONSTANT'], datasets=['inputDataset']),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "Cancellations_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Cancellations\",\n",
    "    metadata=Metadata(input_name=\"Cancellations\", is_required=True, tooltip=\"All Departures_On_Time\", multiple=False, options=['FIELDS', 'CONSTANT'], datasets=['inputDataset']),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "Arrivals_Delayed_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Arrivals_Delayed\",\n",
    "    metadata=Metadata(input_name=\"Arrivals_Delayed\", is_required=True, tooltip=\"All Departures_On_Time\", multiple=False, options=['FIELDS', 'CONSTANT'], datasets=['inputDataset']),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Cancelled_perc_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Cancelled_perc\",\n",
    "    metadata=Metadata(input_name=\"Cancelled_perc\", is_required=True, tooltip=\"Output column\", multiple=False,\n",
    "),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "departure_delay_perc_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"departure_delay_perc\",\n",
    "    metadata=Metadata(input_name=\"departure_delay_perc\", is_required=True, tooltip=\"Output column\", multiple=False, \n",
    "),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "arrival_delay_perc_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"arrival_delay_perc\",\n",
    "    metadata=Metadata(input_name=\"arrival_delay_perc\", is_required=True, tooltip=\"Output column\", multiple=False,\n",
    "),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "Dep_Arr_delay_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Dep_Arr_delay\",\n",
    "    metadata=Metadata(input_name=\"Dep_Arr_delay\", is_required=True, tooltip=\"Output column\", multiple=False,\n",
    "),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "Btwness_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Btwness\",\n",
    "    metadata=Metadata(input_name=\"Btwness\", is_required=True, tooltip=\"Output column\", multiple=False,\n",
    "),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "closeness_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"closeness\",\n",
    "    metadata=Metadata(input_name=\"closeness\", is_required=True, tooltip=\"Output column\", multiple=False, \n",
    "),\n",
    "    local_context=locals()\n",
    ") \n",
    "\n",
    "\n",
    "Deg_centrality_Parameter = Helpers.get_or_create_input_var(\n",
    "    name=\"Deg_centrality\",\n",
    "    metadata=Metadata(input_name=\"Deg_centrality\", is_required=True, tooltip=\"Output column\", multiple=False, \n",
    "),\n",
    "    local_context=locals()\n",
    ") \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label_outputcolumnParameter = Helpers.get_or_create_input_var(\n",
    "    name=\"label\",\n",
    "    metadata=Metadata(input_name=\"label\", is_required=True, tooltip=\"Output column\", multiple=False,\n",
    "),\n",
    "    local_context=locals()\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "outputDatasetParameter=Helpers.get_or_create_output_dataset(\n",
    " name=\"outputDataset2\",\n",
    "    metadata=Metadata(input_name='Clusteres outputDataset2', is_required=True, tooltip='Dataset name to be created after the transformation'),\n",
    "    local_context=locals()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05033bcc",
   "metadata": {},
   "source": [
    "#Getting the context\n",
    "contextId = 'Airline_performance'\n",
    "context = Helpers.getOrCreateContext(contextId=contextId, localVars=locals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aabab58b-aed9-4fb0-a732-5c8c10a31a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the parameters\n",
    "All_airline=inputDatasetParameter.value\n",
    "\n",
    "\n",
    "Airline = Airline_Parameter.value\n",
    "\n",
    "Departures_On_Time =Departures_On_Time_Parameter.value\n",
    "# Departures_Delayed =    Departures_Delayed_Parameter.value\n",
    "# Sectors_Scheduled=    Sectors_Scheduled_Parameter.value\n",
    "# Sectors_Flown=    Sectors_Flown_Parameter.value\n",
    "Cancellations=    Cancellations_Parameter.value\n",
    "# Month_Num = Month_Num_Parameter.value\n",
    "# Year = Year_Parameter.value\n",
    "Arrivals_Delayed = Arrivals_Delayed_Parameter.value\n",
    "# Departing_Port=Departing_Port_Parameter.value\n",
    "# Arriving_Port=Arriving_Port_Parameter.value\n",
    "# useless =useless_Parameter.value()\n",
    "Total_scheduled=Total_scheduled_Parameter.value\n",
    "Total_departed= Total_departed_Parameter.value\n",
    "Cancelled_perc = Cancelled_perc_Parameter.value\n",
    "departure_delay_perc= departure_delay_perc_Parameter.value\n",
    "arrival_delay_perc = arrival_delay_perc_Parameter.value\n",
    "Dep_Arr_delay = Dep_Arr_delay_Parameter.value\n",
    "Btwness = Btwness_Parameter.value\n",
    "closeness = closeness_Parameter.value\n",
    "Deg_centrality = Deg_centrality_Parameter.value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label = label_outputcolumnParameter.value\n",
    "\n",
    "outputDataset2=outputDatasetParameter.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97adea55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'airline_grp'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b79b3f81-239e-4755-8b84-5d0f87cc2f8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m All_airline \u001b[38;5;241m=\u001b[39m \u001b[43mHelpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetEntityData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAll_airline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\utils\\notebookhelpers\\helpers.py:240\u001b[0m, in \u001b[0;36mHelpers.getEntityData\u001b[1;34m(context, entityName, inferDTypesFromSchema, numRows, pandas_lib)\u001b[0m\n\u001b[0;32m    238\u001b[0m     entityDf \u001b[38;5;241m=\u001b[39m Utils\u001b[38;5;241m.\u001b[39mreadCSV(entityPath[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentity_path\u001b[39m\u001b[38;5;124m'\u001b[39m], numRows\u001b[38;5;241m=\u001b[39mnumRows, pandas_lib\u001b[38;5;241m=\u001b[39mpandas_lib)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     entityDf \u001b[38;5;241m=\u001b[39m \u001b[43mUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadParquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentityPath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentity_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumRows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumRows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpandas_lib\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpandas_lib\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m entityDf \u001b[38;5;241m=\u001b[39m FunctionLib\u001b[38;5;241m.\u001b[39msanitize_dataset_col_names(entityDf)\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferDTypesFromSchema:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\utils\\notebookhelpers\\utils.py:134\u001b[0m, in \u001b[0;36mUtils.readParquet\u001b[1;34m(filePath, numRows, pandas_lib)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m numRows \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 134\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilePath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParquetFile\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;124;03mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03mDataFrame\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    491\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\io\\parquet.py:240\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[1;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[0;32m    234\u001b[0m     path,\n\u001b[0;32m    235\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    236\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    237\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    238\u001b[0m )\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[0;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    244\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyarrow\\parquet\\__init__.py:2737\u001b[0m, in \u001b[0;36mread_table\u001b[1;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties)\u001b[0m\n\u001b[0;32m   2730\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2731\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword is no longer supported with the new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2732\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets-based implementation. Specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2733\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to temporarily recover the old \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2734\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehaviour.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2735\u001b[0m     )\n\u001b[0;32m   2736\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2737\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43m_ParquetDatasetV2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2738\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2743\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2744\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2746\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2747\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2748\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\n\u001b[0;32m   2749\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2750\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m   2751\u001b[0m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[0;32m   2752\u001b[0m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[0;32m   2753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyarrow\\parquet\\__init__.py:2340\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.__init__\u001b[1;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, **kwargs)\u001b[0m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2337\u001b[0m     fragment \u001b[38;5;241m=\u001b[39m parquet_format\u001b[38;5;241m.\u001b[39mmake_fragment(single_file, filesystem)\n\u001b[0;32m   2339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mFileSystemDataset(\n\u001b[1;32m-> 2340\u001b[0m         [fragment], schema\u001b[38;5;241m=\u001b[39mschema \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfragment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphysical_schema\u001b[49m,\n\u001b[0;32m   2341\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mparquet_format,\n\u001b[0;32m   2342\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfragment\u001b[38;5;241m.\u001b[39mfilesystem\n\u001b[0;32m   2343\u001b[0m     )\n\u001b[0;32m   2344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2346\u001b[0m \u001b[38;5;66;03m# check partitioning to enable dictionary encoding\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyarrow\\_dataset.pyx:870\u001b[0m, in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyarrow\\error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pyarrow\\error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file."
     ]
    }
   ],
   "source": [
    "All_airline = Helpers.getEntityData(context, All_airline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64476f15-332d-4ea1-b501-efc86e19509d",
   "metadata": {},
   "source": [
    "cust_scaled  = All_airline.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9642c70b-4273-432a-97d3-edbe9e81b583",
   "metadata": {},
   "source": [
    "cust_scaled = All_airline.drop('Airline',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32e284-eb8b-48bf-b4e8-b1ee937cba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate an empty dictionary\n",
    "def clustering(cust_scaled):\n",
    "    wcss = {}\n",
    "\n",
    "    # Elbow method with for loop\n",
    "    # for i in range(1, 11):\n",
    "    #     kmeans = KMeans(n_clusters= i, init= 'k-means++', max_iter= 3000)\n",
    "    #     kmeans.fit(cust_scaled)\n",
    "    #     wcss[i] = kmeans.inertia_\n",
    "\n",
    "    # choose n_clusters = 5\n",
    "    clus = KMeans(n_clusters= 5, init= 'k-means++', max_iter= 3000)\n",
    "    clus.fit(cust_scaled)\n",
    "\n",
    "    KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=3000,\n",
    "        n_clusters=5, n_init=1000,\n",
    "        random_state=None, tol=0.0001, verbose=0)\n",
    "\n",
    "    # Assign the clusters  to original data\n",
    "    # All_airline_grp['K_Cluster'] = clus.labels_\n",
    "    # Assign the clusters to scaled data\n",
    "    cust_scaled[label] = clus.labels_\n",
    "    # cust_scaled.rename(columns = {'K_Cluster':label}, inplace = True)\n",
    "    # cust_scaled.reset_index(drop = True,inplace=True)\n",
    "    return cust_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafea45e-6343-44be-88ab-1ff0f692aa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_scaled= clustering(All_airline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e8ab26-4709-4fb6-883c-7ee7ff3f4158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a205e564-dc6a-4cb9-b156-d20a1cbd37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputCollection = Helpers.createOutputCollection(context)\n",
    "out = Helpers.createTemplateOutputDataset(context=context, outputName=outputDataset2, dataFrame=cust_scaled)\n",
    "outputCollection.addTemplateOutput(out)\n",
    "Helpers.save(context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
